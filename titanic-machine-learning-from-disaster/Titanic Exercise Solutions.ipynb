{"cells":[{"cell_type":"markdown","source":["#Titanic Dataset Exercise"],"metadata":{}},{"cell_type":"markdown","source":["## Import libraries and Data\n- Import the libraries you'll need to perform the exercises\n- Import the data, producing spark dataframes. NB the options used e.g. header. Make sure to display your dataframes to check they are as expected"],"metadata":{}},{"cell_type":"code","source":["\"\"\" Import Libraries \"\"\"\nimport pyspark.sql.functions as f\nimport pyspark.sql.types as t\nfrom pyspark.sql.window import Window\n\n\"\"\" Import the data \"\"\"\n# File location and type\nfile_location = \"/FileStore/tables/\"\nfile_type = \"csv\"\n\n# CSV options\ninfer_schema = \"true\"\nfirst_row_is_header = \"true\"\ndelimiter = \",\"\n\n# The applied options are for CSV files. For other file types, these will be ignored.\ndf_train = spark.read.format(file_type) \\\n  .option(\"inferSchema\", infer_schema) \\\n  .option(\"header\", first_row_is_header) \\\n  .option(\"sep\", delimiter) \\\n  .load(file_location + 'train.csv')\n\ndf_test = spark.read.format(file_type) \\\n  .option(\"inferSchema\", infer_schema) \\\n  .option(\"header\", first_row_is_header) \\\n  .option(\"sep\", delimiter) \\\n  .load(file_location + 'test.csv')\n\ndf_gender_schema = t.StructType([\n                    t.StructField(\"PassengerId\", t.IntegerType()),\n                    t.StructField(\"Survived\", t.IntegerType())\n                ])\n\ndf_gender = spark.read.format(file_type) \\\n  .option(\"inferSchema\", False) \\\n  .option(\"header\", first_row_is_header) \\\n  .option(\"sep\", delimiter) \\\n  .schema(df_gender_schema) \\\n  .load(file_location + 'gender_submission.csv')\n\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"code","source":["df_train.show(n=5, truncate = False)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----------+--------+------+---------------------------------------------------+------+----+-----+-----+----------------+-------+-----+--------+\nPassengerId|Survived|Pclass|Name                                               |Sex   |Age |SibSp|Parch|Ticket          |Fare   |Cabin|Embarked|\n+-----------+--------+------+---------------------------------------------------+------+----+-----+-----+----------------+-------+-----+--------+\n1          |0       |3     |Braund, Mr. Owen Harris                            |male  |22.0|1    |0    |A/5 21171       |7.25   |null |S       |\n2          |1       |1     |Cumings, Mrs. John Bradley (Florence Briggs Thayer)|female|38.0|1    |0    |PC 17599        |71.2833|C85  |C       |\n3          |1       |3     |Heikkinen, Miss. Laina                             |female|26.0|0    |0    |STON/O2. 3101282|7.925  |null |S       |\n4          |1       |1     |Futrelle, Mrs. Jacques Heath (Lily May Peel)       |female|35.0|1    |0    |113803          |53.1   |C123 |S       |\n5          |0       |3     |Allen, Mr. William Henry                           |male  |35.0|0    |0    |373450          |8.05   |null |S       |\n+-----------+--------+------+---------------------------------------------------+------+----+-----+-----+----------------+-------+-----+--------+\nonly showing top 5 rows\n\n</div>"]}}],"execution_count":4},{"cell_type":"markdown","source":["##Questions\n### 1) Excluding the child passengers (Age < 18) find the the minimum, maximum, and average fares for each passenger class."],"metadata":{}},{"cell_type":"markdown","source":["1) Create a complete dataset by: <br>\n<Tab> a. Join `df_gender` with `df_test` on `PassengeId` <br>\n<Tab> b. Append the dataframe from a with `df_train`\n  \nTip: Check that the transformations you are doing produce the expected output e.g. by checking number of rows, columns, schema.\n  \n2) Filter the complete dataframe `df` selecting only passenger with `Age < 18`, aggregate by `Pclass` calculating the minimum, maximum and average fares."],"metadata":{}},{"cell_type":"code","source":["# Join df_gender to df_test\ndf_join = df_test.join(df_gender, df_test.PassengerId == df_gender.PassengerId, 'left_outer').drop(df_gender.PassengerId)\n\n#Check we have the same number of rows in df_join as df_test since we are using a left outer join.\nassert df_join.count() == df_gender.count()\n\n# Union the df_train with df_join\ndf = df_train.unionAll(df_join.select(*df_train.columns))\n\n#Check we get the correct number of rows and the schema is correct\nassert df.count() == df_train.count() + df_join.count()\nassert df.schema == df_train.schema\ndf.show(n = 5, truncate = False)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----------+--------+------+---------------------------------------------------+------+----+-----+-----+----------------+-------+-----+--------+\nPassengerId|Survived|Pclass|Name                                               |Sex   |Age |SibSp|Parch|Ticket          |Fare   |Cabin|Embarked|\n+-----------+--------+------+---------------------------------------------------+------+----+-----+-----+----------------+-------+-----+--------+\n1          |0       |3     |Braund, Mr. Owen Harris                            |male  |22.0|1    |0    |A/5 21171       |7.25   |null |S       |\n2          |1       |1     |Cumings, Mrs. John Bradley (Florence Briggs Thayer)|female|38.0|1    |0    |PC 17599        |71.2833|C85  |C       |\n3          |1       |3     |Heikkinen, Miss. Laina                             |female|26.0|0    |0    |STON/O2. 3101282|7.925  |null |S       |\n4          |1       |1     |Futrelle, Mrs. Jacques Heath (Lily May Peel)       |female|35.0|1    |0    |113803          |53.1   |C123 |S       |\n5          |0       |3     |Allen, Mr. William Henry                           |male  |35.0|0    |0    |373450          |8.05   |null |S       |\n+-----------+--------+------+---------------------------------------------------+------+----+-----+-----+----------------+-------+-----+--------+\nonly showing top 5 rows\n\n</div>"]}}],"execution_count":7},{"cell_type":"code","source":["# Filter for over 18s, Use groupBy and agg functions to aggregate over class using pyspark sql functions min, max, mean\ndf_agg_fare = df.where(df.Age>=18).groupBy(['Pclass']).agg(f.round(f.min('Fare'),2).alias('min_fare'),\n                                                 f.round(f.max('Fare'),2).alias('max_fare'),\n                                                 f.round(f.mean('Fare'),2).alias('mean_fare'))\ndf_agg_fare.show()\n\n#Using sql\ndf.createOrReplaceTempView('table_df')\nsql_query = 'SELECT Pclass, round(min(Fare),2) as min_fare, round(max(Fare),2) as max_fare, round(avg(Fare),2) as mean_fare FROM table_df WHERE Age >= 18 GROUP BY Pclass'\nspark.sql(sql_query).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------+--------+--------+---------+\nPclass|min_fare|max_fare|mean_fare|\n+------+--------+--------+---------+\n     1|     0.0|  512.33|     90.9|\n     3|     0.0|    56.5|    10.91|\n     2|    9.69|    73.5|    20.72|\n+------+--------+--------+---------+\n\n+------+--------+--------+---------+\nPclass|min_fare|max_fare|mean_fare|\n+------+--------+--------+---------+\n     1|     0.0|  512.33|     90.9|\n     3|     0.0|    56.5|    10.91|\n     2|    9.69|    73.5|    20.72|\n+------+--------+--------+---------+\n\n</div>"]}}],"execution_count":8},{"cell_type":"markdown","source":["### 2) Produce a summary with the survival rates for each passenger gender, with survival rate as a %?"],"metadata":{}},{"cell_type":"code","source":["# Aggregate by by gender and survived indicator\ndf_survival = df.groupBy(['Sex','Survived']).agg(f.count('Sex').alias('count')) \\\n                .withColumn('gender_total',f.sum(f.col('count')).over(Window.partitionBy(f.col('Sex'))))\ndf_survival.show()\n\n# Calculate the survival rate\ndf_survival_rate = df_survival.withColumn('survival_rate (%)',f.round((f.col('count')/f.col('gender_total'))*100,2))\\\n                              .where(f.col('Survived') == 1)\\\n                              .select('Sex','survival_rate (%)')\ndf_survival_rate.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------+--------+-----+------------+\n   Sex|Survived|count|gender_total|\n+------+--------+-----+------------+\nfemale|       1|  385|         466|\nfemale|       0|   81|         466|\n  male|       0|  734|         843|\n  male|       1|  109|         843|\n+------+--------+-----+------------+\n\n+------+-----------------+\n   Sex|survival_rate (%)|\n+------+-----------------+\nfemale|            82.62|\n  male|            12.93|\n+------+-----------------+\n\n</div>"]}}],"execution_count":10},{"cell_type":"markdown","source":["### BONUS - Produce a summary of the passenger cabins. How will you handle missing values?"],"metadata":{}},{"cell_type":"code","source":["df_cabin = df.select('PassengerId','Pclass','Fare',\n                    f.when(f.col('Cabin').isNull(),'N/A').otherwise(f.col('Cabin').substr(0,1)).alias('Cabin_Letter')\n                    )\ndf_cabin.show(n=5)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----------+------+-------+------------+\nPassengerId|Pclass|   Fare|Cabin_Letter|\n+-----------+------+-------+------------+\n          1|     3|   7.25|         N/A|\n          2|     1|71.2833|           C|\n          3|     3|  7.925|         N/A|\n          4|     1|   53.1|           C|\n          5|     3|   8.05|         N/A|\n+-----------+------+-------+------------+\nonly showing top 5 rows\n\n</div>"]}}],"execution_count":12},{"cell_type":"code","source":["# Create a pivot table to show the classes who stay in each floor\ndf_cabin_summary = df_cabin.groupBy(['Cabin_Letter']).pivot('Pclass').agg(f.count(\"PassengerId\")).orderBy('Cabin_Letter')\n\n# Create \ndf_cabin_fare = df_cabin.groupBy('Cabin_Letter').agg(f.round(f.mean('Fare'),2).alias('Avg_Price'))\ndf_cabin_summary = df_cabin_summary.join(df_cabin_fare,df_cabin_summary.Cabin_Letter == df_cabin_fare.Cabin_Letter,'left_outer').select(df_cabin_summary.Cabin_Letter,'1','2','3','Avg_Price')\ndf_cabin_summary.show()\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------------+----+----+----+---------+\nCabin_Letter|   1|   2|   3|Avg_Price|\n+------------+----+----+----+---------+\n           A|  22|null|null|    41.24|\n           B|  65|null|null|   122.38|\n           C|  94|null|null|   107.93|\n           D|  40|   6|null|    53.01|\n           E|  34|   4|   3|    54.56|\n           F|null|  13|   8|    18.08|\n           G|null|null|   5|    14.21|\n         N/A|  67| 254| 693|    19.13|\n           T|   1|null|null|     35.5|\n+------------+----+----+----+---------+\n\n</div>"]}}],"execution_count":13},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":14}],"metadata":{"name":"Titanic Exercise Solutions","notebookId":2465182520589767},"nbformat":4,"nbformat_minor":0}
